{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "5e72df66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5514fce1",
   "metadata": {},
   "source": [
    "## **User Define Class**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "5849e2e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# åˆ›å»ºç±»\n",
    "class Data_Class:\n",
    "\n",
    "    # å†…éƒ¨åµŒå¥—ç±»\n",
    "    class Trajectory_Class:\n",
    "        def __init__(self, traj_series):\n",
    "            self.traj_list = traj_series\n",
    "            self.length = len(traj_series)\n",
    "\n",
    "        def get_single_traj(self, index):\n",
    "            return json.loads(self.traj_list[index])\n",
    "\n",
    "    def __init__(self, path):\n",
    "        self.path = path\n",
    "\n",
    "        # åŸå§‹æ•°æ®\n",
    "        self.trajs_prefer_list = []\n",
    "        self.trajs_reject_list = []\n",
    "\n",
    "        # å¤„ç†æ•°æ®\n",
    "        self.traj_prefer_list_list_tensor = []\n",
    "        self.traj_reject_list_list_tensor = []\n",
    "\n",
    "        # å¯åŠ¨å‡½æ•°\n",
    "        self.load_data(path)\n",
    "        self.convert(self.trajs_prefer_list, self.traj_prefer_list_list_tensor) # æ•°æ®è½¬æ¢\n",
    "        self.convert(self.trajs_reject_list, self.traj_reject_list_list_tensor)\n",
    "        print(\"Data loaded successfully\")\n",
    "\n",
    "    def load_data(self, path):\n",
    "        data = pd.read_csv(path)\n",
    "\n",
    "        self.trajs_prefer_list = Data_Class.Trajectory_Class(data['preferred'])   # list æ•°æ®\n",
    "        self.trajs_reject_list = Data_Class.Trajectory_Class(data['rejected'])    # list æ•°æ®\n",
    "\n",
    "    def convert(self,\n",
    "                list_json: Trajectory_Class,\n",
    "                traj_list_list_tensor):\n",
    "\n",
    "        # è·å–ç¬¬0æ¡è½¨è¿¹çš„ç¬¬0æ—¶åˆ»æ ·æœ¬æ¥ç¡®å®šç»´åº¦\n",
    "        sample = list_json.get_single_traj(0)[0]\n",
    "        state0 = np.array(sample['state'])\n",
    "        action0 = np.array(sample['action'])\n",
    "\n",
    "        # è·å– state action ç»´åº¦\n",
    "        self.dim_state = state0.size if state0.ndim == 0 else state0.shape[0]\n",
    "        self.dim_action = action0.size if action0.ndim == 0 else action0.shape[0]\n",
    "\n",
    "        # æ•°æ®æ‰¹é‡è½¬æ¢ tensor\n",
    "        for idx in range(list_json.length):\n",
    "            traj = list_json.get_single_traj(idx)\n",
    "            states, actions = [], []\n",
    "\n",
    "            for time_i in traj:\n",
    "                # è½¬æ¢ä¸º numpyï¼Œç„¶å torch tensor\n",
    "                state_np = np.array(time_i['state'])\n",
    "                action_np = np.array(time_i['action'])\n",
    "\n",
    "                state_t = torch.from_numpy(state_np).float()\n",
    "                action_t = torch.from_numpy(action_np).float()\n",
    "\n",
    "                # å¦‚æœæ˜¯ä¸€ç»´æ ‡é‡ï¼Œè¦å±•å¼€æˆé•¿åº¦1å‘é‡\n",
    "                state_t = state_t.view(-1)\n",
    "                action_t = action_t.view(-1)\n",
    "\n",
    "                states.append(state_t)\n",
    "                actions.append(action_t)\n",
    "\n",
    "            # å°†åˆ—è¡¨å †æˆå¼ é‡ [L_i, dim]\n",
    "            states_tensor = torch.stack(states, dim=0)\n",
    "            actions_tensor = torch.stack(actions, dim=0)\n",
    "\n",
    "            # å°†æ¯æ¡è½¨è¿¹ä½œä¸ºä¸€ä¸ªå…ƒç»„ (states, actions) æ·»åŠ åˆ°åˆ—è¡¨ä¸­\n",
    "            traj_list_list_tensor.append((states_tensor, actions_tensor))\n",
    "\n",
    "# â€”â€”â€” æ•°æ®é›†ä¸åŠ è½½å™¨ â€”â€”â€”\n",
    "class PreferenceDataset(Dataset):\n",
    "    def __init__(self, pref, rej, gamma):\n",
    "        assert len(pref) == len(rej)\n",
    "        self.pref = pref\n",
    "        self.rej = rej\n",
    "        self.gamma = gamma\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.pref)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return (*self.pref[idx], *self.rej[idx])\n",
    "\n",
    "# åˆ›å»º MLP æ‰“åˆ†æ¨¡å‹\n",
    "class RewardMLP(nn.Module):\n",
    "    def __init__(self, s_dim, a_dim, hidden_dim=64):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(s_dim + a_dim, hidden_dim),  # è¿™é‡Œåœ¨æ„é€ ç¥ç»ç½‘ç»œ\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, s, a):\n",
    "        # s: [L_i, s_dim], a: [L_i, a_dim]\n",
    "        x = torch.cat([s, a], dim=-1)\n",
    "        return self.net(x).squeeze(-1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "b8606d68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded successfully\n",
      "200 200\n",
      "200 144\n",
      "200 180\n",
      "\n",
      "200 200\n",
      "200 144\n"
     ]
    }
   ],
   "source": [
    "# â€”â€”â€”â€” åŠ è½½æ•°æ® â€”â€”â€”â€”\n",
    "path = \"trajectory_pairs.csv\"\n",
    "Data = Data_Class(path)\n",
    "\n",
    "print(len(Data.trajs_prefer_list.get_single_traj(0)),  len(Data.trajs_reject_list.get_single_traj(0)))\n",
    "print(len(Data.trajs_prefer_list.get_single_traj(1)),  len(Data.trajs_reject_list.get_single_traj(1)))\n",
    "print(len(Data.trajs_prefer_list.get_single_traj(2)),  len(Data.trajs_reject_list.get_single_traj(2)))\n",
    "print(\"\")\n",
    "print(len(Data.traj_prefer_list_list_tensor[0][0]), len(Data.traj_reject_list_list_tensor[0][0]))\n",
    "print(len(Data.traj_prefer_list_list_tensor[1][0]), len(Data.traj_reject_list_list_tensor[1][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0eeca22",
   "metadata": {},
   "source": [
    "## **Training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "b87a9072",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded successfully\n",
      "Epoch 1/50 â€” Avg Loss: 0.5030\n",
      "Epoch 2/50 â€” Avg Loss: 0.3736\n",
      "Epoch 3/50 â€” Avg Loss: 0.3204\n",
      "Epoch 4/50 â€” Avg Loss: 0.2934\n",
      "Epoch 5/50 â€” Avg Loss: 0.2803\n",
      "Epoch 6/50 â€” Avg Loss: 0.2708\n",
      "Epoch 7/50 â€” Avg Loss: 0.2642\n",
      "Epoch 8/50 â€” Avg Loss: 0.2583\n",
      "Epoch 9/50 â€” Avg Loss: 0.2534\n",
      "Epoch 10/50 â€” Avg Loss: 0.2486\n",
      "Epoch 11/50 â€” Avg Loss: 0.2452\n",
      "Epoch 12/50 â€” Avg Loss: 0.2420\n",
      "Epoch 13/50 â€” Avg Loss: 0.2389\n",
      "Epoch 14/50 â€” Avg Loss: 0.2363\n",
      "Epoch 15/50 â€” Avg Loss: 0.2346\n",
      "Epoch 16/50 â€” Avg Loss: 0.2330\n",
      "Epoch 17/50 â€” Avg Loss: 0.2311\n",
      "Epoch 18/50 â€” Avg Loss: 0.2293\n",
      "Epoch 19/50 â€” Avg Loss: 0.2277\n",
      "Epoch 20/50 â€” Avg Loss: 0.2264\n",
      "Epoch 21/50 â€” Avg Loss: 0.2246\n",
      "Epoch 22/50 â€” Avg Loss: 0.2240\n",
      "Epoch 23/50 â€” Avg Loss: 0.2226\n",
      "Epoch 24/50 â€” Avg Loss: 0.2212\n",
      "Epoch 25/50 â€” Avg Loss: 0.2211\n",
      "Epoch 26/50 â€” Avg Loss: 0.2179\n",
      "Epoch 27/50 â€” Avg Loss: 0.2195\n",
      "Epoch 28/50 â€” Avg Loss: 0.2177\n",
      "Epoch 29/50 â€” Avg Loss: 0.2173\n",
      "Epoch 30/50 â€” Avg Loss: 0.2158\n",
      "Epoch 31/50 â€” Avg Loss: 0.2142\n",
      "Epoch 32/50 â€” Avg Loss: 0.2127\n",
      "Epoch 33/50 â€” Avg Loss: 0.2118\n",
      "Epoch 34/50 â€” Avg Loss: 0.2113\n",
      "Epoch 35/50 â€” Avg Loss: 0.2101\n",
      "Epoch 36/50 â€” Avg Loss: 0.2094\n",
      "Epoch 37/50 â€” Avg Loss: 0.2091\n",
      "Epoch 38/50 â€” Avg Loss: 0.2080\n",
      "Epoch 39/50 â€” Avg Loss: 0.2071\n",
      "Epoch 40/50 â€” Avg Loss: 0.2060\n",
      "Epoch 41/50 â€” Avg Loss: 0.2058\n",
      "Epoch 42/50 â€” Avg Loss: 0.2049\n",
      "Epoch 43/50 â€” Avg Loss: 0.2045\n",
      "Epoch 44/50 â€” Avg Loss: 0.2060\n",
      "Epoch 45/50 â€” Avg Loss: 0.2043\n",
      "Epoch 46/50 â€” Avg Loss: 0.2035\n",
      "Epoch 47/50 â€” Avg Loss: 0.2020\n",
      "Epoch 48/50 â€” Avg Loss: 0.2024\n",
      "Epoch 49/50 â€” Avg Loss: 0.2002\n",
      "Epoch 50/50 â€” Avg Loss: 0.1996\n",
      "ğŸ‰ åˆæˆæ•°æ®ä¸Šçš„å¥–åŠ±æ¨¡å‹è®­ç»ƒå®Œæˆï¼\n",
      "æ¨¡å‹å·²ä¿å­˜åˆ° reward_net.pth\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# â€”â€”â€”â€” è¶…å‚æ•° â€”â€”â€”â€”\n",
    "num_pairs = 200    # åå¥½å¯¹æ•°é‡\n",
    "T = 50             # æœŸæœ›æœ€å¤§è½¨è¿¹é•¿åº¦ï¼ˆç”¨äºè¯„ä¼°æˆ–å…¶ä»–éœ€æ±‚ï¼‰\n",
    "s_dim = 4         # çŠ¶æ€ç»´åº¦ [è§’åº¦, è§’é€Ÿåº¦, å°è½¦ä½ç½®, å°è½¦é€Ÿåº¦]\n",
    "a_dim = 1         # åŠ¨ä½œç»´åº¦ï¼ˆæ¨åŠ›ï¼‰\n",
    "gamma = 0.99      # æŠ˜æ‰£å› å­\n",
    "lr = 1e-4         # å­¦ä¹ ç‡\n",
    "batch_size = 16\n",
    "num_epochs = 50\n",
    "\n",
    "# â€”â€”â€”â€” åŠ è½½æ•°æ® â€”â€”â€”â€”\n",
    "path = \"trajectory_pairs.csv\"\n",
    "Data = Data_Class(path)\n",
    "\n",
    "# è‡ªå®šä¹‰ collate_fnï¼Œä¿ç•™å˜é•¿åºåˆ—\n",
    "def variable_collate(batch):\n",
    "    # batch: List of tuples (s_pref, a_pref, s_rej, a_rej)\n",
    "    s_pf, a_pf, s_rj, a_rj = zip(*batch)\n",
    "    return list(s_pf), list(a_pf), list(s_rj), list(a_rj)\n",
    "\n",
    "# å‡†å¤‡è®­ç»ƒ\n",
    "dataset = PreferenceDataset(\n",
    "    Data.traj_prefer_list_list_tensor,\n",
    "    Data.traj_reject_list_list_tensor,\n",
    "    gamma\n",
    ")\n",
    "loader = DataLoader(\n",
    "    dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    collate_fn=variable_collate\n",
    ")\n",
    "\n",
    "reward_net = RewardMLP(Data.dim_state, Data.dim_action, hidden_dim=64)\n",
    "optimizer  = optim.Adam(reward_net.parameters(), lr=lr)\n",
    "loss_fn    = nn.BCEWithLogitsLoss()\n",
    "\n",
    "# â€”â€”â€” è®­ç»ƒå¾ªç¯ â€”â€”â€”\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    total_loss = 0.0\n",
    "    for s_pref_list, a_pref_list, s_rej_list, a_rej_list in loader:\n",
    "        R_pref_batch = []\n",
    "        R_rej_batch  = []\n",
    "\n",
    "        # è®¡ç®— prefer è½¨è¿¹çš„å›æŠ¥\n",
    "        for s_pf, a_pf in zip(s_pref_list, a_pref_list):\n",
    "            r_pf = reward_net(s_pf, a_pf)           # [L_i]\n",
    "            discounts = torch.tensor([gamma**t for t in range(r_pf.size(0))], device=r_pf.device)\n",
    "            R_pref_batch.append((r_pf * discounts).sum())\n",
    "\n",
    "        # è®¡ç®— reject è½¨è¿¹çš„å›æŠ¥\n",
    "        for s_rj, a_rj in zip(s_rej_list, a_rej_list):\n",
    "            r_rj = reward_net(s_rj, a_rj)          # [L_j]\n",
    "            discounts = torch.tensor([gamma**t for t in range(r_rj.size(0))], device=r_rj.device)\n",
    "            R_rej_batch.append((r_rj * discounts).sum())\n",
    "\n",
    "        R_pref = torch.stack(R_pref_batch)\n",
    "        R_rej = torch.stack(R_rej_batch)\n",
    "\n",
    "        logits = R_pref - R_rej\n",
    "        targets = torch.ones_like(logits)        # pref åº”å¾—æ›´é«˜åˆ†\n",
    "        loss = loss_fn(logits, targets)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item() * len(R_pref_batch)\n",
    "\n",
    "    avg_loss = total_loss / len(dataset)\n",
    "    print(f\"Epoch {epoch}/{num_epochs} â€” Avg Loss: {avg_loss:.4f}\")\n",
    "\n",
    "print(\"ğŸ‰ åˆæˆæ•°æ®ä¸Šçš„å¥–åŠ±æ¨¡å‹è®­ç»ƒå®Œæˆï¼\")\n",
    "\n",
    "# â€”â€”â€” ä¿å­˜æ¨¡å‹ â€”â€”â€”\n",
    "torch.save(reward_net.state_dict(), 'reward_net.pth')\n",
    "print(\"æ¨¡å‹å·²ä¿å­˜åˆ° reward_net.pth\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da3a6bec",
   "metadata": {},
   "source": [
    "## **Load Grading Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "9ec08b06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "åŠ è½½å¹¶å‡†å¤‡å¥½è¿›è¡Œæ¨ç†\n",
      "æŠ˜æ‰£åæ€»å›æŠ¥ï¼š tensor(18.6901)\n"
     ]
    }
   ],
   "source": [
    "# å‡è®¾ä½ å·²æœ‰ä¸€æ¡è½¨è¿¹çš„åŸå§‹ JSON æ•°æ® traj_json\n",
    "traj_json = Data.trajs_prefer_list.get_single_traj(2)\n",
    "traj_json = Data.trajs_reject_list.get_single_traj(2)\n",
    "\n",
    "# æŠŠå®ƒè½¬æˆå¼ é‡\n",
    "states  = torch.stack([torch.from_numpy(np.array(step['state'])).float().view(-1)\n",
    "                       for step in traj_json], dim=0)  # [L, s_dim]\n",
    "actions = torch.stack([torch.from_numpy(np.array(step['action'])).float().view(-1)\n",
    "                       for step in traj_json], dim=0)  # [L, a_dim]\n",
    "\n",
    "\n",
    "\n",
    "# â€”â€”â€” åŠ è½½æ¨¡å‹ç¤ºä¾‹ â€”â€”â€”\n",
    "reward_net_loaded = RewardMLP(Data.dim_state, Data.dim_action, hidden_dim=64)\n",
    "reward_net_loaded.load_state_dict(torch.load('reward_net.pth', weights_only=True))\n",
    "\n",
    "# åˆ‡åˆ°æ¨ç†æ¨¡å¼ï¼Œå¹¶å…³é—­æ¢¯åº¦\n",
    "reward_net_loaded.eval()\n",
    "print(\"åŠ è½½å¹¶å‡†å¤‡å¥½è¿›è¡Œæ¨ç†\")\n",
    "with torch.no_grad():\n",
    "    per_step_rewards = reward_net_loaded(states, actions)  # å¼ é‡å½¢çŠ¶ [L]\n",
    "\n",
    "# å¦‚æœä½ æƒ³è¦è½¨è¿¹çš„æ€»æŠ˜æ‰£å›æŠ¥ï¼š\n",
    "discounts = torch.tensor([gamma**t for t in range(per_step_rewards.size(0))])\n",
    "total_return = (per_step_rewards * discounts).sum()\n",
    "# print(\"æ¯æ­¥å¥–åŠ±ï¼š\", per_step_rewards)\n",
    "print(\"æŠ˜æ‰£åæ€»å›æŠ¥ï¼š\", total_return)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
